{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#  Personal  Details  #\n",
    "#######################\n",
    "\n",
    "### Name: \n",
    "### Email:\n",
    "### Phone No.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "\n",
    "The dataset is small. It contains the following 20 categories:\n",
    "\n",
    "- bike\n",
    "- crab\n",
    "- ipod\n",
    "- license-plate\n",
    "- owl\n",
    "- playing-card\n",
    "- raccoon\n",
    "- smokestack\n",
    "- spaghetti\n",
    "- syringe\n",
    "- chandelier\n",
    "- grapes\n",
    "- ketch\n",
    "- octopus\n",
    "- paperclip\n",
    "- pyramid\n",
    "- skateboard\n",
    "- soda-can\n",
    "- speed-boat\n",
    "- umbrella\n",
    "\n",
    "The training data contains the above-mentioned 20 categories, with 40 images in each category (800 images total). The testing data includes 40 unclassified images\n",
    "\n",
    "\n",
    "### Get the dataset\n",
    "\n",
    "The dataset is located in an S3 bucket (in one of our AWS accounts). For the purpose of this challenge, these images are made publicly accessible to you. For example, one of the images could be viewed via https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic/bike/bike0001.jpg.\n",
    "\n",
    "Each image can be downloaded from a URL, with the following naming convention:\n",
    "\n",
    "**training data**\n",
    "```\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic/<category>/<category><index>.jpg\n",
    "\n",
    "for example,\n",
    "\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic/octopus/octopus0001.jpg\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic/octopus/octopus0002.jpg\n",
    "...\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic/octopus/octopus0010.jpg\n",
    "...\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic/umbrella/umbrella0040.jpg\n",
    "```\n",
    "\n",
    "**testing data**\n",
    "```\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic-test/<index>.jpg\n",
    "\n",
    "for example,\n",
    "\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic-test/1.jpg\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic-test/2.jpg\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic-test/3.jpg\n",
    "...\n",
    "https://s3-us-west-2.amazonaws.com/lnh-challenge/dataset/ic-test/40.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks - Image Classification\n",
    "Use the provided training data, create a model and classify the unlabeled testing data. In specific, you are exepected to perform the following tasks:\n",
    "\n",
    "1. Download the above-mentioned dataset.\n",
    "2. Organize and prepare training data for training.\n",
    "3. Upload the training data to S3 with the appropriate folder structure.\n",
    "4. Train a model with the training data. \n",
    "5. Perform predictions for the testing data. Output the results including label and accuracy.\n",
    "6. Output the result labels and accuracy into a CSV file.  Use this CSV file to either run a query on Athena or Quicksight.  Take screenshot of the results for submission at the end of the exercise. \n",
    "\n",
    "Bonus points will be given to the following tasks:\n",
    "\n",
    "7. Tune Hyperparameters for better performance.\n",
    "8. Train a new model with the improved Hyperparameters. \n",
    "9. Perform predictions for the testing data (with the improved model). Output the results including label and accuracy.\n",
    "10. Output the results in step 5 and step 9 into CSV files. Perform queries against the CSV using Athena and / or  perform visualization for the CSV using QuickSight showing differences in accuracy due to tuning hyperparamaters. \n",
    "\n",
    "It is very important that the notebook captures your attempts (and results) as much as possible. This gives us more insight into your thinking and experiment process. For example, if you write some code in a cell but it is not running as expected, please do not redo the same thing in the same cell. Instead, add a new cell below the current cell **(Menu -> Insert -> Insert Cell Below)** and continue your work in the new cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5d04e42a3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a is'\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "print('a is'  + a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is 1\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "print('a is ' + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if you do have used Terminal in this notebook for some work, do include a code cell which contains the commands you have used, and use comment to describe what has been done. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have made a directory in the Terminal on this instance\n",
    "\n",
    "# mkdir -p ~/SageMaker/mydata/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "- At the end of the challenge, download the current notebook **(Menu -> File -> Download as -> Notebook (.ipynb))** for submission. The downloaded notebook should include all the execution details for our review. As such, it is very important that you DO NOT clear any of the outputs in the notebook. Rename the downloaded notebook to \"challenge-__*yourname*__.ipynb\" (e.g. challenge-jiaxili.ipynb).\n",
    "    \n",
    "- For step 9, take screenshots and insert them into a Word .docx file. Please make sure that you have the appropriate documentation for each of the screenshots. \n",
    "\n",
    "- Zip/Tar the above-mentioned .ipynb and .docx files together. Submit via email to aws-learn-bigdata-101@amazon.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start your work below\n",
    "\n",
    "#### Add comments to your code as much as possible. This will allow the reviewer to understand the intention of your code, even if it is not working as expected.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "# setting the epoch value so we'll train only 3 epochs\n",
    "epoch = 3\n",
    "\n",
    "# getting the configured epoch value, and output to stdout \n",
    "print(\"number of epoch is \" + epoch)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Download the dataset. \n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Organize/Prepare the data for SageMaker training. \n",
    "# Hint. You can train with image lst format as what we have done on Friday.\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Upload to S3 with the correct folder structure. \n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Start training job. \n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Perform predictions for the testing data. \n",
    "# Output the results including label and accuracy.  \n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (bonus) Tune Hyperparameters for better performance.\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Traing a new model with the new Hyperparameters. \n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Perform predictions for the testing data with the improved model. \n",
    "# Output the results including label and accuracy. ##########\n",
    "# Hint. Try to do this task with real-time inference option\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Output the results in step 5 and step 8 into CSV files. \n",
    "# Perform queries against the CSV using Athena. \n",
    "# Perform visualization for the CSV using QuickSight. \n",
    "# Use screeshots to capture your results if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Up\n",
    "\n",
    "It is very important that you clean up the AWS resources you are using after this challenge. This includes the endpoints, the notebook instance, and the data stored in your S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
